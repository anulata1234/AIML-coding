{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "1  396.90   4.98  24.0  \n",
       "2  396.90   9.14  21.6  \n",
       "3  392.83   4.03  34.7  \n",
       "4  394.63   2.94  33.4  \n",
       "5  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"housing.csv\",index_col=0)  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=smf.ols('medv~crim+zn+chas+indus+age+nox+rm+dis+rad+tax+ptratio+black+lstat',df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>medv</td>       <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 03 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:13:59</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crim</th>      <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zn</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chas</th>      <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>indus</th>     <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nox</th>       <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rm</th>        <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>       <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tax</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ptratio</th>   <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lstat</th>     <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   medv   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Wed, 03 Apr 2019   Prob (F-statistic):          6.72e-135\n",
       "Time:                        12:13:59   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "crim          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "zn             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "chas           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "indus          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "age            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "nox          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "rm             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "dis           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "rad            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "tax           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "ptratio       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "black          0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "lstat         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['medv'],axis=1)\n",
    "Y=df[['medv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardSfrom sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegressioncaler()\n",
    "X=sc.fit_transform(X)\n",
    "Y=sc.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LinearRegression()\n",
    "knn=KNeighborsRegressor(n_neighbors=3)\n",
    "bag_knn=BaggingRegressor(base_estimator=knn,n_estimators=30,random_state=0)\n",
    "\n",
    "# Base estimator is Decision Tree as as a regressor\n",
    "bag_dt=BaggingRegressor(n_estimators=51,random_state=0)\n",
    "boost_dt=AdaBoostRegressor(n_estimators=51,random_state=0)\n",
    "\n",
    "bag_LR=BaggingRegressor(base_estimator=LR,n_estimators=50,random_state=0)\n",
    "boost_LR=AdaBoostRegressor(base_estimator=LR,n_estimators = 50,random_state=0)\n",
    "\n",
    "gboost=GradientBoostingRegressor(n_estimators=100,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: 0.52 (+/- 0.00721) [LinearReg]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: 0.52 (+/- 0.00728) [BaggedLR]\n",
      "RMSE scores: 0.55 (+/- 0.00511) [BoostedLR]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: 0.36 (+/- 0.00326) [BaggedDT]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: 0.39 (+/- 0.00319) [BoostedDT]\n",
      "RMSE scores: 0.44 (+/- 0.00767) [KNN]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: 0.44 (+/- 0.00682) [BaggedKNN]\n",
      "RMSE scores: 0.32 (+/- 0.00153) [GradientBoost]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "kf=KFold(n_splits=5,shuffle=True,random_state=2)\n",
    "for model, name in zip([LR,bag_LR,boost_LR,bag_dt,boost_dt,knn,bag_knn,gboost],\n",
    "        ['LinearReg','BaggedLR','BoostedLR','BaggedDT','BoostedDT','KNN','BaggedKNN','GradientBoost']):\n",
    "    rmse=[]\n",
    "    for train,test in kf.split(X,Y):\n",
    "        Xtrain,Xtest=X[train,:],X[test,:]\n",
    "        Ytrain,Ytest=Y[train],Y[test]\n",
    "        model.fit(Xtrain,Ytrain)\n",
    "        Y_predict=model.predict(Xtest)\n",
    "        #mse=np.sum((Ytest-Y_predict)**2)/len(Ytest)\n",
    "        mse=metrics.mean_squared_error(Ytest,Y_predict)\n",
    "        rmse.append(np.sqrt(mse))\n",
    "    print(\"RMSE scores: %0.02f (+/- %0.5f) [%s]\" % (np.mean(rmse), np.var(rmse,ddof=1), name ))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21384615384615382"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.0065-.00511)/.0065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('Simple_Linear_Regression',LR))\n",
    "models.append(('AdaBoost_Reg_using_DT',abreg_dt))\n",
    "models.append(('AdaBoost_Reg_using_LR',abreg_LR))\n",
    "models.append(('GradientBoost_Reg',gbreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple_Linear_Regression: -1.584199 (9.180153)\n",
      "AdaBoost_Reg_using_DT: 0.505715 (0.082197)\n",
      "AdaBoost_Reg_using_LR: -2.047845 (12.239849)\n",
      "GradientBoost_Reg: 0.577598 (0.049991)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHVBJREFUeJzt3XmYHVWd//H3hzUqCIkJhi1EZHHF\nzNAuMLggiMj4gDiMqCigM0Zx13HcUAk6LqPDOPwElwyDQRQFEVAEZdOAICgdDQkRRIQgYZFmkRAI\nYfv+/jjn0tXN7e7b6ZNeTn9ez9NP31tV99Spc6s+de6puygiMDOzeq031hUwM7N1y0FvZlY5B72Z\nWeUc9GZmlXPQm5lVzkFvZlY5B721JWmBpP9YR2UfIun8Qea/QtKKdbHuiU7SJyWdMNb1sInFQT/J\nSVoo6R5JG4/WOiPiexGxT6MOIWmH0Vq/kvdLulrS/ZJWSPqhpOePVh3WVkR8ISL+dazrYROLg34S\nkzQbeCkQwP6jtM4NRmM9QzgW+ADwfmAasBNwFvCPY1mpoYyTtrMJyEE/uR0KXAEsAA4bbEFJH5V0\nm6RbJf1rsxcuaTNJ35HUI+kmSZ+StF6ed7ikyyR9VdLdwLw87dI8/5K8iqskrZJ0cGOd/ybpjrze\ntzWmL5D0dUk/y4+5TNJMSf+TX51cK+nvBtiOHYH3AG+KiF9ExJqIeCC/yvjSMLfnb5JukLR7nn5z\nru9h/er6TUkXSLpP0sWStmvMPzY/bqWkRZJe2pg3T9Lpkr4raSVweJ723Tx/Sp53V67LlZKenudt\nJeknku6WdL2kd/Qr97S8jfdJWiapa7Dn3yY2B/3kdijwvfz36lZI9CdpX+DDwN7ADsDL+y3yNWAz\nYPs871DgbY35LwZuALYAPt98YES8LN98QURsEhGn5vszc5lbA/8CHC9pauOhbwA+BUwH1gCXA7/L\n908H/nuAbd4LWBERvx1gfqfbswR4GnAK8APghaS2eQtwnKRNGssfAnwu120xqb1brgTmkF5ZnAL8\nUNKUxvwD8vZs3u9xkE7OmwHb5rq8C1id530fWAFsBRwEfEHSXo3H7p/rvTnwE+C4QdrDJjgH/SQl\naQ9gO+C0iFgE/Bl48wCLvwH4dkQsi4gHgKMb5awPHAx8IiLui4jlwDHAWxuPvzUivhYRj0TEajrz\nMPDZiHg4Is4FVgE7N+afGRGLIuJB4EzgwYj4TkQ8CpwKtO3RkwLxtoFW2uH23BgR326sa9tc1zUR\ncT7wECn0W86JiEsiYg1wJLCbpG0BIuK7EXFXbptjgI37beflEXFWRDzWpu0eztuzQ0Q8mttjZS57\nD+BjEfFgRCwGTui3DZdGxLl5G04GXjBQm9jE56CfvA4Dzo+IO/P9Uxh4+GYr4ObG/ebt6cBGwE2N\naTeReuLtlu/UXRHxSOP+A0Czl/zXxu3Vbe43l+1TLrDlIOvtZHv6r4uIGGz9j29/RKwC7ia1aWt4\n6hpJ90r6G6mHPr3dY9s4GTgP+EEeUvuypA1z2XdHxH2DbMPtjdsPAFN8DaBeDvpJSNKTSL30l0u6\nXdLtwIeAF0hq17O7DdimcX/bxu07ST3L7RrTZgG3NO6Pp69IvQjYZpAx6U62Z7geb688pDMNuDWP\nx3+M9FxMjYjNgXsBNR47YNvlVztHR8RzgN2B15KGmW4FpknatOA22ATmoJ+cXgc8CjyHND48B3g2\n8CtSUPR3GvA2Sc+W9GTgM60Z+aX/acDnJW2aLzR+GPjuMOrzV9J4+DoXEX8Cvg58X+n9+hvli5pv\nlPTxQtvT336S9pC0EWms/jcRcTOwKfAI0ANsIOkzwFM7LVTSnpKen4ebVpJOUI/msn8NfDFv2y6k\n6xz9x/htknDQT06Hkcbc/xIRt7f+SBfkDun/Ej4ifgb8P+CXwPWkC5+QLoICvA+4n3TB9VLSMNCJ\nw6jPPOCk/M6RN6zlNg3H+0nbejzwN9L1iQOBs/P8kW5Pf6cAR5GGbHYlXZyFNOzyM+A60tDKgwxv\nmGsm6ULtSuAa4GJ6T0hvAmaTevdnAkdFxAUj2AabwOQfHrHhkvRs4Gpg437j6NaPpAWkd/l8aqzr\nYpOXe/TWEUkH5mGOqcB/Amc75M0mBge9deqdpLHkP5PG948Y2+qYWac8dGNmVjn36M3MKuegNzOr\nnIPezKxyDnozs8o56M3MKuegNzOrnIPezKxyDnozs8o56M3MKuegNzOrnIPezKxyDnozs8o56M3M\nKuegNzOr3Jj+6vv06dNj9uzZY1kFM7MJZdGiRXdGxIzhPGZMg3727Nl0d3ePZRXMzCYUSTcN9zEe\nujEzq1yxoJd0oqQ7JF1dqkwzMxu5kj36BcC+BcszM7MCigV9RFwC3F2qPDMzK2PUx+glzZXULam7\np6dntFdvZjbpjHrQR8T8iOiKiK4ZM4b1DiEzM1sLfteNmVnlHPRmZpUr+fbK7wOXAztLWiHpX0qV\nbRODpKJ/ZlZGsU/GRsSbSpVlE1NEDLmMpI6WMyupdMdhou3DY/oVCGZmo6HTYK61I+IxejOb0KZN\nm1Z0uLBEOdOmTRvjVunLPXob0rRp07jnnnuKlVfqZfTUqVO5+25/Rm+yu+eee8ZdL3y8XWNy0NuQ\nxuOBBOPvYDIbrxz0ZjahxVFPhXmbjXU1+oijnjrWVehjUgf9ZL8Sb1YDHb1y3B17koh5Y12LXvUG\nfQdn+OJn3U56FfPuLbvOUTAee0ww/npNZuOVxvJM2NXVFevqF6bG49ukxmOdOjFe6z1e61WCX212\nbjzuB+uyTpIWRUTXcB5Tb4/ebAKb7O/7Hq7xdmF+6tSpY12FPhz0ZqPMb1ctq+SJrtYTp4PebJT5\n7ao22hz01pHxGALj7eVxp3xx20abg96G5JfGZY3HtwPC+HtLoJXjoDez6g3nFWkny47HE/VgHPRm\nVr2JFsyl+dsrzcwqVzToJe0r6Y+Srpf08ZJl2/hX+mtgzayMYkM3ktYHjgdeBawArpT0k4j4Q6l1\n2Pg22V8em41XJXv0LwKuj4gbIuIh4AfAAQXLNzOztVAy6LcGbm7cX5GnmZnZGCoZ9O0GVZ/wWl7S\nXEndkrp7enoKrt7MzNopGfQrgG0b97cBbu2/UETMj4iuiOiaMWNGwdWbmVk7JYP+SmBHSc+QtBHw\nRuAnBcs3M7O1UOxdNxHxiKT3AucB6wMnRsSyUuWbmdnaKfrJ2Ig4Fzi3ZJlmZjYy/mSsmVnlHPRm\nZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9\nmVnlHPRmZpVz0JuZVc5Bb2ZWuSJBL+mfJS2T9JikrhJlmplZGaV69FcDrwcuKVSemZkVUuSnBCPi\nGgBJJYozM7OCPEZvZla5jnv0ki4EZraZdWRE/HgY5cwF5gLMmjWr04eZmdla6jjoI2LvEiuMiPnA\nfICurq4oUaaZmQ3MQzdmZpUr9fbKAyWtAHYDzpF0Xolyzcxs5Eq96+ZM4MwSZZmZWVkeujEzq5yD\n3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrn\noDczq5yD3syscg56M7PKOejNzCrnoDczq1ypnxL8iqRrJS2RdKakzUuUa2ZmI1eqR38B8LyI2AW4\nDvhEoXLNzGyEigR9RJwfEY/ku1cA25Qo18zMRm5djNG/HfjZQDMlzZXULam7p6dnHazezMyaNuh0\nQUkXAjPbzDoyIn6clzkSeAT43kDlRMR8YD5AV1dXDKu2ZmY2bB0HfUTsPdh8SYcBrwX2iggHuJnZ\nONFx0A9G0r7Ax4CXR8QDJco0M7MySo3RHwdsClwgabGkbxYq18zMRqhIjz4idihRjpmZledPxpqZ\nVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnlinzX\nzXglaayr0MfUqVPHugpmNglVG/SlvhJfUrGyzMzGgoduzMwq56A3M6ucg97MrHJFgl7S5yQtyb8u\ndb6krUqUa2ZmI1eqR/+ViNglIuYAPwU+U6hcMzMboSJBHxErG3efAvhtKmZm40Sxt1dK+jxwKHAv\nsOcgy80F5gLMmjWr1OrNzGwA6vQ94pIuBGa2mXVkRPy4sdwngCkRcdRQZXZ1dUV3d3endR0Tfh+9\nlTZe96nxWi/rS9KiiOgazmM67tFHxN4dLnoKcA4wZNCbmdm6V+pdNzs27u4PXFuiXDMzG7lSY/Rf\nkrQz8BhwE/CuQuWamdkIFQn6iPinEuWYmVl5/mSsmVnlHPRmZpVz0JuZVa7a76M3G8/G24/igH8Y\np2YOerNRVvJDSf6Qk3XCQzdmZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnl\nHPRmZpVz0JuZVc5Bb2ZWuaJBL+kjkkLS9JLlmpnZ2isW9JK2BV4F/KVUmWZmNnIle/RfBT4K+Kv0\nzMzGkSJBL2l/4JaIuKqDZedK6pbU3dPTU2L1ZmY2iI6/j17ShcDMNrOOBD4J7NNJORExH5gP0NXV\n5d6/mdk61nHQR8Te7aZLej7wDOCq/Ks52wC/k/SiiLi9SC3NzGytjfgXpiJiKbBF676k5UBXRNw5\n0rLNzGzk/D56M7PKFf/N2IiYXbpMMzNbe+7Rm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5\nB72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlSsS9JLm\nSbpF0uL8t1+Jcs3MbORK/sLUVyPivwqWZ2ZmBXjoxsysciWD/r2Slkg6UdLUguWamdkIdBz0ki6U\ndHWbvwOAbwDPBOYAtwHHDFLOXEndkrp7enpGvAFmZjY4RUTZAqXZwE8j4nlDLdvV1RXd3d1F11+a\nJEq3kVkp3j8nH0mLIqJrOI8p9a6bLRt3DwSuLlGumZmNXKl33XxZ0hwggOXAOwuVa2ZmI1Qk6CPi\nrSXKMTOz8vz2SjOzyjnozcwq56A3M6ucg97MrHIOejOzyjnozcwq56A3M6ucg97MrHIOejOzyjno\nzcwq56A3M6ucg97MrHIOejOzyjnozcwq56A3M6ucg97MrHLFgl7S+yT9UdIySV8uVa6ZmY1MkV+Y\nkrQncACwS0SskbRFiXLXNUlFl/OPNJvZeFTqN2OPAL4UEWsAIuKOQuWuUw5mM5sMSg3d7AS8VNJv\nJF0s6YWFyjUzsxHquEcv6UJgZptZR+ZypgIvAV4InCZp+2jTZZY0F5gLMGvWrLWps5mZDUPHQR8R\new80T9IRwBk52H8r6TFgOtDTppz5wHyArq4uj52Yma1jpYZuzgJeCSBpJ2Aj4M5CZZuZ2QiUuhh7\nInCipKuBh4DD2g3bmJnZ6CsS9BHxEPCWEmWZmVlZ/mSsmVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnl\nHPRmZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZW\nOQe9mVnlivzClKRTgZ3z3c2Bv0XEnBJlm5nZyJT6KcGDW7clHQPcW6JcMzMbuVI/Dg6AJAFvAF5Z\nslwzM1t7RYMeeCnw14j400ALSJoLzAWYNWtW4dWb1SH1mcotGxEjqY5NcB0HvaQLgZltZh0ZET/O\nt98EfH+wciJiPjAfoKury3ufWRsOZiup46CPiL0Hmy9pA+D1wK4jrZSZmZVT8u2VewPXRsSKgmWa\nmdkIlQz6NzLEsI2ZmY2+YhdjI+LwUmWZmVk5/mSsmVnlHPRmZpVz0JuZVc5Bb2ZWOY3lBzMk9QA3\njVkFOjMduHOsK1ERt2dZbs+yJkJ7bhcRM4bzgDEN+olAUndEdI11PWrh9izL7VlWre3poRszs8o5\n6M3MKuegH9r8sa5AZdyeZbk9y6qyPT1Gb2ZWOffozcwq56A3M6tcR0Ev6UhJyyQtkbRY0oslnSDp\nOSUqIWlVqcdJepekQ0deq7Wqz3JJS3M7XSxpuw4fd6CkkPSsAeYvkHTQEGUskHRjfn6ulXRUm2XW\n+jmT9LqhHtuvDldJ2mtt1jVSjfY8XtITfkdhJO0p6dE8bVnexg9LWk/Sq/P0xZJWSfpjvv2dAcqf\nMO3ZqM9n27Vnm+WeLukUSTdIWiTpckkHDrBsu2N4nqRb8nb/QdLpkj4ynDoMsK45kvZr3D9cUk/j\n+Txd0pPXpuxO1jfAMs06XCvpQ6XW30dEDPoH7AZcDmyc708HthrqccP5A1aN5uNGWFcB6w0wbzkw\nPd8+GvjfDss8DfgVMG+A+ScBBw1RxoLWMsAU4AbgGQW3e8Ew67An8KfRfn46bM/hbsvj7dnc54At\ngAuBo/s9diHQVUt7DrPtlfPiXY1p2wHv67fcBvn/E45hYB7wkXx7R2AN8NECdTscOG6Q+6cAbyvY\nFn3KH2oZ4GmkD2ttW/x56aCyrwfObjP98Z0ZWAX8J7Ao7/gvyvNvAPZvbNCPgZ8DfwSOapTVPHj+\nHbgSWNL/AGpTh6F2koW5Xr8FrgNemqevD3ylsZ535umbABcBvwOWAgfk6bOBa4CvA78nfTKtXX2W\n0xv0+wLnNua9JddjMfAtYP08/d3Aw8BvgL8Bx+WD5RrgrvzE3wAcApwI3ALcT/pE8Xzgubncu/O0\nHYGtgAeAZcDVwOdyvVfl52Bj0s8+3gCsBnpy2RvnZX4NPJjX83Vg91z+jbn+zxxg+xfQNxwfaMzb\nFbg47yPnAVvm6S/Mz8Hl+Tm5ehgH6k+BV+Tnc0He1mW5HXcC7gUOyu25Mm/nvfn2+3MZX8rTVgN/\nyG04vd+2bJ7baovcPnvl9lwK/DA/T2pMf7ydG+v4Q97O/5pg7bkU+FCb+iwndWZax8qzGnlxT57+\nrVZ7Ntb3Q+Bs4Bek4+0Rnni8zQN+RsqJC/NzM69NHQZqg4X0O+6BjYC/kPaBxcDB9A3ZDfJz9rp8\nfztSFizJ/2cNMf2fc3tdBVzSbn0dPgdXAC/Kt2cAPyLl1JXAPzSmX9CujUcS9Jvkil5HOuhf3ibo\nA3hNvn0mcD6wIfACYHFjg24jnbWelBvl8RNF/r8PKbxEGlb6KfCyEQb9Mfn2fsCF+fZc4FP59sZA\nN6m3tgHw1Dx9OnB9rsts4DHgJUO01XJ6d+r/Aebm288m7dwb5vtfBw4lBXIPcHJur5XAqaSD5da8\n/duQgusM0sliGil4riP1QM4mnQQWkILjKtKB8ftGQKwgBd9C4BzgM6Sd8JZct18AvwQ+mJ/LFXm7\nvwz8R/8DbJDtf3wZ4HXAKfn2hqSTx4x8/2DgxHz7amD3RiCuTTDtClwQvSfUk/PtO0gdh9fnNnk/\nvSfB1r7wv8An8u2L8va3gr4VxKuAL7T2OeBmYKd8/zu5vFmt6Y12/mB+vv5I7zvcNp9I7TlQnUn7\n+vvy7XcDJ+TblwCX5tv7ttqzsb4VwLRGuLaO/ebx9i1SVjyZFNKr6T2mF5BO3oO1wULaH/f9t/dw\neoP4r6RXga0O2NnAYfn224Gzhpi+FNi6X3v1Wd9QzwFpH1oMTMn3TwH2aMy7Jt8+jt59tk8bD/Q3\n5A+PRMQqSbvmBt8TOFXSx/st9hCpp97a4DUR8bCkpaSQbLkgIu4CkHQGsAcpZFv2yX+/z/c3IfVQ\nLxmqnoM4I/9f1KjLPsAujXHazfJ6VgBfkPQyUrBvDTw9L3NTRFzRwfp+KenppJD5VJ62F+nguVIS\npBPdHaRXPmuA7+T2Oj/X42WkHuQPI2KFpF+QTpo7kXrnW5B29M1IIf1J0sFwTEQcJ2kOcIWkk0nh\ndUNEXJfX/VPSSeYqYLOIuEbS90g7zMtIz+VdwAmkE8xWHWxz01ckfTnX8SV52s7A84ALch3WB26T\ntDmwaUT8Oi93CvDaYa4PUlttL+lrwIvpbfcbSfvY1qRXJz+KiFsl/SbXD9JPYN4r6c2kUF7dKPff\nI+J0SZsAF0nandQBuTEirsvLnET6dbVntqY32vlVpIPyQeAESefk6cMx1u15Dqnj1k7z2Hp9vr09\nqXdNRPxc0hpgoaTVwPGkDLg7LytgI0lL6Hu8bQc8hZQD2wNntVl32zYYoG6zB9nWUyPivUqFHE/q\nGHyJNGTd2qaTSZ0eBpl+GbBA0mmNdXfqYEl75m16R0Q8mKfvDTwnbx/AUyVtStqnD4TH2/ieoVbQ\n0cXYiHg0IhZGxFHAe4F/6rfIw5FPL6QnbE1+3GP0/RWr6Pe4/vcFfDEi5uS/HSLi/zqp4yDW5P+P\nNuoiUm+ktZ5nRMT5pJ7xDGDXiJhDOstPyY+5v8P17UnaUZcBn22s76TG+naOiHnApsBMUggsJ50Q\ndszLt1vnm0i9nGdFxEbAN0i9xf3z9n1a0isjojU8tAHwAVJvoFMPk05APyKdnF4zjMdCOlB2IIXt\nSXmagGWN7X9+ROxD73Z26hH67rNTACLiHtKJsDvX+Yzcns8jDZO01tPaFwJYX9IU0iumd0fE80m9\n+yfUKSJWkXqJe7Sp05a5vLYHW0Q8Qm97vo7eDlGnxrI9FwLvIZ3022l3bK0htXvLA6RgbH0JV3Of\nPiTXud3xdkVE7Ezqqe/LE38Nb6A2GKxuA8r5dTaps9N2kcGmR8S7SM/RtsBiSU8bap0Np0bEc0md\n6WMkzczT1wN2a2zj1hFxH8N/nocOekk7S9qxMWkOa/+Nk6+SNE3Sk0g7/WX95p8HvD33oJC0taQt\n+hdSwHnAEZI2zOvZSdJTSD3kO3LvuhXYwxYRq0kv2w+VNI3Uqz6otS25DbYj9ZZXk9p0B9K430rS\n+O0zgPUkbUk6eVwFvC+v4s7cuzwImErqgV1DGsfbRdK2wN8BpwNfALaQtEN+7H7AucAupF7bTqQT\nyDTSeCeknv65pJfJ0/K0+0gnpk62/zHg2Fz/V5NORjMk7Za3f0NJz82Bcp+kVk/1jUMUvRyYk9/l\nsi0pQJE0nbQvTyENHV4fEbNJ48F3kNrzKfS2Z+tLq6aQTmx75n3ucHqD5nGSNiC9UvgzqSMzW9IO\nkmaQxoJ/CVzbmp4fth9wcS631Z4fJD3XMAHaMyJ+BHwa+PtO6pn9HNhS0hGS9iHtn08aYNnN0uY9\n4Xi7CXhezokLSMHW/4vG2rbBEHUbqs33ID3HkIaFWu13CHDpYNMlPTMifhMRnyFfUO1gfX1ExOWk\nVwkfyJPOJ3Wsyeto7TuXAm/I01ptPGThQ43R75o3rnUx6QzSeNpC+o2xR78x8uY80kF0Guml4GAX\nYz9AGv5ZSrqg1PZCVV72MdJwS+vvwzxxjL5Vx+nA8nx7PVIALiWNaf6StNNNz+vsJvViriG97JvN\nIGOdjfospzFWBnwN+HT0jiEuzm24iPQyfCHpAL4u3/4G6ST0jbzum0kvW88C3kzqpd9B6q30AN8m\nXaxaRgqzB/I23UTa2RaTwv8Inngx9s20vxh7P+ki1pJczq9y/f8h7wO/H+g5od+4M+mV30X59hzS\nENxVub7vyNNfTO/Fwy8Clw3SvgK+lx9/am6zV5B6n7/L2/dneq8XLQD+L7fnStJ+d1Z+3LK8zH/n\ndluZy70vt8MCesfo/5CfS5F6iNfndlud26o1pvqEi7GkHn+rPZfSO747Edpzcf57Tf/60Pd6VBew\nMN/egjTWfTfpIvdDudw+Fz8bx2TkZe4nnXQ/R9+LsefntryDdNw26zBQGyyk/XE/jXQ8NC/Gtsbo\nl5A6QFvkZWeThkX7X3QdaPoZ9ObJsblt+6xvgOegf5tsBdxOOkFMz8/LEtK+8s1GG7feNPJV0vW8\njQfLplH7CgRJh5Ma/71DLTuZSNok0nWQDUi90RMj4syxrtdoaW1/vv1x0jsnPjDEw0quf2Pg0Yh4\nJPcOvxFpGGFCcnvWb23aeMixK1vn5il9AGQKqffS7sJTzf5R0idI++JNpB7OaJoFnCZpPVLP8h2j\nvP7S3J71G3Ybj/svNcsXNS5qM2uvyO/gGW35XRsb95v81ohYOhb1GW2SjicNPTQdGxHfLlT+q0lj\n3003RkTbT1eWNtr7nNuzfpLeRu/Ye8tlEfGeUVn/eA96MzMbGX+pmZlZ5Rz0ZmaVc9CbmVXOQW9m\nVjkHvZlZ5f4/492qoFJ+k9YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=3,random_state=2)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, np.mean(cv_results), np.var(cv_results))\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81781693, 0.63555614, 0.27941997])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xnew=X[:500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ynew=Y[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 13)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ynew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xprod=X[501:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yprod=Y[501:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/python3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=2, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the best model before delivery\n",
    "gbreg.fit(Xnew,Ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20318981,  0.02696698,  0.82286285,  0.48693929, -0.00583182])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_value_predicted=gbreg.predict(Xprod)\n",
    "housing_value_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.3997166 , 22.78057925, 30.09327973, 27.00681014, 22.47922346])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_value_predicted_in_real_units=sc.inverse_transform(housing_value_predicted)\n",
    "housing_value_predicted_in_real_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.4],\n",
       "       [20.6],\n",
       "       [23.9],\n",
       "       [22. ],\n",
       "       [11.9]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yprod_in_real_units=sc.inverse_transform(Yprod)\n",
    "Yprod_in_real_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.157826187467221"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((housing_value_predicted-Yprod)**2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
